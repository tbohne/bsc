\section{Stacking-Probleme}
\label{sec:stacking_problems}

Stacking-Probleme treten in der Praxis zum Beispiel im Umfeld von Lagerhallen und Container-Terminals auf.
Ankommende \textit{Items}, häufig Container, müssen sogenannten \textit{Stacks} zugeordnet werden, sodass bestimmte Nebenbedingungen respektiert werden. Diese Nebenbedingungen sorgen zum Beispiel dafür, dass nicht jedes \textit{Item} auf jedem anderen \textit{Item} platziert werden
darf. Es wird dabei angenommen, dass die im Folgenden als \textit{Storage-Area} bezeichnete Lagerfläche in festen
\textit{Stacks} organisiert ist, die eine limitierte gemeinsame Höhe besitzen, die im Folgenden als \textit{Stack}-Kapazität bezeichnet wird.
In der Regel kann nur auf das oberste \textit{Item} eines \textit{Stacks} zugegriffen werden, d.h. der \textit{Item}-Zugriff erfolgt
nach dem \textquote{Last-In–First-Out}-Prinzip. Ein Zugriff auf \textit{Items} darunter erfordert eine sogenannte \textit{Relocation}-Operation,
die zeit- und energieaufwendig ist.

In dieser Arbeit wird nur der \textit{Loading}-Prozess betrachtet, währenddem keine \textit{Item}-Entnahme stattfindet.
Die \textit{Items} werden dabei in die \textit{Storage-Area} geladen, die aus \textit{Stacks} mit einer festen Position besteht, d.h.
man kann die \textit{Stacks} nicht positionieren, sondern lediglich den \textit{Items} eine Position in einem \textit{Stack} zuweisen.
Der \textit{Relocation}-Prozess wird typischerweise durch Kräne durchgeführt, die den \textit{Stacks} eine Maximalhöhe auferlegen.

Neben der Tatsache, dass nicht jedes \textit{Item} auf jedem anderen \textit{Item} platziert werden darf, gilt auch, dass es \textit{Items} gibt, die auf bestimmte Positionen beschränkt sind, weil sie zum Beispiel eine Energiequelle benötigen.
Abbildung \ref{fig:storage_area} zeigt den Aufbau der \textit{Storage-Area} bestehend aus $m$ fixierten
\textit{Stacks}, die jeweils $b$ \textit{Level} enthalten. Jedes \textit{Level} innerhalb eines \textit{Stacks} entspricht dabei einer Position, der ein \textit{Item} zugeordnet werden kann.

\begin{figure}[H]
\centering
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{|c|c|c|c|c|c|}
\cline{1-5}
$\boldsymbol{S_1}$ & $\boldsymbol{S_2}$ & $\boldsymbol{S_3}$ & ... & $\boldsymbol{S_m}$\\ \cline{1-5}
\end{tabular}}
\caption*{\textsc{Draufsicht}}
\end{figure}
\begin{figure}[H]
\centering
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{c|c|c|c|c|c|}
\cline{2-6}
$\boldsymbol{L_b}$ & $pos_{1, b}$ & $pos_{2, b}$ & $pos_{3, b}$ & ... & $pos_{m, b}$ \\ \cline{2-6}
... & ... & ... & ... & ... & ...\\ \cline{2-6}
$\boldsymbol{L_2}$ & $pos_{1, 2}$ & $pos_{2, 2}$ & $pos_{3, 2}$ & ... & $pos_{m, 2}$\\ \cline{2-6}
$\boldsymbol{L_1}$ & $pos_{1, 1}$ & $pos_{2, 1}$ & $pos_{3, 1}$ & ... & $pos_{m, 1}$\\ \cline{2-6}
\multicolumn{1}{c}{} & \multicolumn{1}{c}{$\boldsymbol{S_1}$} & \multicolumn{1}{c}{$\boldsymbol{S_2}$}
& \multicolumn{1}{c}{$\boldsymbol{S_3}$} & \multicolumn{1}{c}{...} & \multicolumn{1}{c}{$\boldsymbol{S_m}$} \\
\end{tabular}}
\caption*{\textsc{Seitenansicht}}

\caption{\textsc{Aufbau der \textit{Storage-Area}}.}
\label{fig:storage_area}
\end{figure}

Das Ziel von Stacking-Problemen ist es, jedes ankommende \textit{Item} einer zulässigen Position in einem
\textit{Stack} zuzuordnen, sodass eine gegebene Zielfunktion optimiert wird. Es gibt eine ganze Reihe praktisch relevanter Zielfunktionen,
in dieser Arbeit geht es allerdings ausschließlich um die Minimierung der Transportkosten, die bei der Verladung der \textit{Items} von ihrer Originalposition zur zugewiesenen Stackposition entstehen.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Formale Definition}
\label{sec:formal_definition}

Die \textit{Storage-Area} besteht aus \textit{Stacks}, die in einer Reihe angeordnet sind (vgl. Abb. \ref{fig:storage_area}).
Prinzipiell kann es mehrere Reihen von Stacks geben, da sich die Schwierigkeit des Problems dadurch jedoch nicht verändert,
wird im Folgenden immwer von einer Reihe von Stacks ausgegangen.
Die $x$-Koordinate spezifiziert jeweils den \textit{Stack} und die $y$-Koordinate den \textit{Level} innerhalb des jeweiligen \textit{Stacks}. Es handelt sich also um eine Reihe von $m$ \textit{Stacks} mit jeweils $b$ Positionen pro \textit{Stack}. Abb. \ref{fig:parameters} zeigt eine Liste der
Parameter, die im weiteren Verlauf der Arbeit verwendet werden, um Stacking-Probleme zu definieren.
\begin{figure}[H]
\centering
\resizebox{0.6\textwidth}{!}{
\begin{tabular}{ | l | l |}
    \hline
    \textbf{Parameter} & \textbf{Semantik} \\ \hline
    $n$ & Anzahl der Items \\ \hline
    $m$ & Anzahl der Stacks \\ \hline
    $b$ & Stack Kapazität \\ \hline
    $I$ & Menge der Items $ I := \{1, 2, ..., n\}$ \\ \hline
\end{tabular}}
\caption{\textsc{Zur Definition verwendete Parameter}.}
\label{fig:parameters}
\end{figure}
In der Regel gilt $m < n$, d.h. es müssen \textit{Items} gestapelt werden.
Außerdem muss die Annahme $n \leq bm$ gelten, denn sonst ist die Instanz des Problems unzulässig,
weil es mehr \textit{Items} als verfügbare Positionen gibt.\newline
Für jedes \textit{Item} $i \in I$ ist dessen Originalposition $O_i$ auf dem Fahrzeug, mit welchem es geliefert wird,
in $x$- und $y$-Koordinaten gegeben.

Neben den in Abb. \ref{fig:parameters} aufgeführten Parametern, gibt es Nebenbedingungen, die beim Lösen der Stacking-Probleme
berücksichtigt werden müssen. Zum einen die in Abschnitt \ref{sec:stacking_restrictions} vorgestellten Stacking Constraints $s_{ij}$,
bei denen es sich um Restriktionen handelt, die angeben, ob ein Item $i \in I$ direkt auf einem anderen Item $j \in I$ platziert werden darf.
Dies ist der Fall, wenn $s_{ij} = 1$ gilt.
Zum anderen die Placement Constraints $t_{iq}$, die in Kapitel \ref{sec:placement_restrictions} thematisiert werden und bei denen
es darum geht, dass manche Items Restriktionen bezüglich ihrer Positionierung besitzen. Ein Item $i \in I$ ist nur dann mit einem Stack
$q \in Q$ kompatibel, wenn $t_{iq} = 1$ gilt.

\textit{Items}, die in einem \textit{Stack} platziert werden, sind durch ein Tupel $(i_k, ..., i_1)$ definiert, wobei
$i_\lambda$ das \textit{Item} auf \textit{Level} $\lambda$ beschreibt. $\lambda = 1$ beschreibt den \textit{Ground-Level}.
Ein Tupel ist zulässig, wenn $k \leq b$ und $s_{i_{\lambda + 1}, i_\lambda} = 1 \quad \forall \quad \lambda = 1, ..., k - 1$.
D.h. ein Tupel ist dann zulässig, wenn die \textit{Stack}-Kapazität eingehalten wird und alle \textit{Items}, die aufeinander gestapelt sind,
nicht den Stacking Constraints widersprechen. Außerdem müssen sämtliche \textit{Item}-\textit{Stack}-Zuweisungen den Placement Constraints entsprechen, d.h. für alle $i_\lambda$ eines Tupels bzw. Stacks $q \in Q$ muss gelten $t_{i_\lambda q} = 1$. Jedes Item muss also mit dem Stack, dem es zugewiesen wurde, kompatibel sein.

\pagebreak

\textbf{Formulierung des Problems}\newline
Gegeben sei eine Menge $I = \{1, ..., n\}$ von \textit{Items} und eine Menge $Q = \{1, ..., m\}$ von \textit{Stacks} mit einer \textit{Stack}-Kapazität von $b$. Außerdem seien \textit{Stacking Constraints} $s_{ij}$ und \textit{Placement Constraints} $t_{iq}$ gegeben.
Das Ziel ist nun, jedes \textit{Item} $i \in I$ genau einem \textit{Stack} $q \in Q$ zuzuweisen, wobei die \textit{Stacking Constraints} $s_{ij}$,
die \textit{Placement Constraints} $t_{iq}$ und die \textit{Stack}-Kapazität $b$ respektiert werden und gegebenenfalls eine Zielfunktion optimiert wird.

\section{Transportkosten}
\label{sec:transport_costs}
Die Transportkosten beziehen sich auf die Kosten, die bei der Verladung der \textit{Items} in die \textit{Storage-Area} entstehen
und sind praktisch zum Beispiel durch Kranbetriebskosten, Wartezeiten oder Arbeitszeiten motiviert.\newline
Jeder \textit{Stack} $q \in Q$ besitzt eine fixierte Position $F_q$ in der \textit{Storage-Area}.
Außerdem besitzt jedes \textit{Item} $i \in I$ eine gegebene Originalposition $O_i$ auf dem Fahrzeug, mit dem es geliefert wird.
Die Kosten ergeben sich aus der Manhattan-Distanz zwischen \textit{Item}- und zugewiesener \textit{Stack}-Position, da diese der Kranbewegung entspricht. In Abb. \ref{fig:costs} ist ein Beispielszenario visualisiert, in welchem die \textit{Items} auf Zügen geliefert und dann durch Kräne auf die ihnen zugewiesenen \textit{Stack}positionen in der \textit{Storage-Area} verladen werden.
\begin{figure}[H]
\includegraphics[width=\textwidth]{img/costs.png}
\caption{Schematische Darstellung eines Bahn-Terminals \cite{Briskorn2018}.}
\label{fig:costs}
\end{figure}
Die Transportkosten werden in einer Matrix $C = (c_{iq})_{n \times m}$ kodiert, \newline wobei $c_{iq} \coloneqq d_{man}(O_i, F_q)$.
D.h. der Eintrag an der Stelle $c_{iq}$ entspricht den Kosten für den Transport des \textit{Items} $i$ in den \textit{Stack} $q$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Nebenbedingungen}
\label{sec:constraints}

\subsection{Stacking Restriktionen}
\label{sec:stacking_restrictions}

Es gibt in der Praxis vielfältige Gründe dafür, dass nicht jedes \textit{Item} auf jedes andere \textit{Item} gestapelt werden darf.
Aus diesen resultieren bestimmte Restriktionen, die z.B. wie folgt lauten:
\begin{itemize}
  \item schwerere \textit{Items} dürfen nicht auf leichteren \textit{Items} platziert werden
  \item größere \textit{Items} dürfen nicht auf kleineren \textit{Items} platziert werden
  \item \textit{Items} bestimmter Materialien oder Zielorte dürfen nicht aufeinander gestapelt werden
\end{itemize}

All jene Restriktionen, die im Folgenden stets als \textit{Stacking Constraints} bezeichnet werden, werden in einer Binärmatrix $S = (s_{ij})_{n \times n}$ kodiert, wobei:
\[
    s_{ij} =
\begin{cases}
    1, & \text{wenn $i$ direkt auf $j$ gestapelt werden darf }\\
    0, & \text{sonst}
\end{cases}
\]
Diese Matrix lässt sich, wie in Abb. \ref{fig:matrix_to_graph} beispielhaft dargestellt,
als gerichteter Graph mit $n$ Knoten für alle $i \in I$ und Kanten $i \rightarrow j$ für alle $s_{ij} = 1$ repräsentieren.
\begin{figure}[H]
  \begin{subfigure}[b]{0.5\textwidth}
  \centering
    $S =$
    $\left(
    \begin{array}{rrrr}
    0 & 1 & 1 & 0 \\
    1 & 0 & 1 & 0 \\
    1 & 0 & 0 & 0 \\
    1 & 1 & 1 & 0 \\
    \end{array} \right) $
    \caption{\textsc{Constraint Matrix}}
    \label{fig:constraint_matrix}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.5\textwidth}
  \centering
    \begin{tikzpicture}[->, scale=0.50, transform shape, node distance=2.5cm]
    \node[state] (A) {1};
    \node[state] (B) [right of=A] {2};
    \node[state] (C) [below of=A] {3};
    \node[state] (D) [right of=C] {4};

    \path (A) edge node {} (B)
          (A) edge node {} (C)

          (B) edge [bend right] node {} (A)
          (B) edge [bend left=10] node {} (C)

          (C) edge [bend left] node {} (A)

          (D) edge [bend left=10] node {} (A)
          (D) edge node {} (B)
          (D) edge node {} (C);
  \end{tikzpicture}
    \caption{\textsc{Resultierender Graph}}
    \label{fig:resulting_graph}
  \end{subfigure}
  \caption{\textsc{Repräsentation der Stacking Constraints.}}
  \label{fig:matrix_to_graph}
\end{figure}
In dieser Arbeit werden ausschließlich transitive \textit{Stacking Constraints} betrachtet, d.h.
wenn \textit{Item} $i$ auf \textit{Item} $j$ und \textit{Item} $j$ auf \textit{Item} $h$ gestapelt werden darf,
so darf auch \textit{Item} $i$ auf \textit{Item} $h$ gestapelt werden.\newline
Diese Eigenschaft ist auch in der Praxis häufig gegeben.
Restriktionen bezüglich des Gewichts und der Länge haben die besondere Eigenschaft, dass alle Items vergleichbar sind, d.h. für alle $i \neq j  \quad \text{gilt} \quad s_{ij} = 1 \quad \text{oder} \quad s_{ji} = 1$, was bedeutet, dass diese Restriktionen eine totale Ordnung auf allen \textit{Items} definieren.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Placement Restriktionen}
\label{sec:placement_restrictions}

Die im Folgenden als \textit{Placement Constraints} bezeichneten Einschränkungen bezüglich der Position eines \textit{Items} resultieren z.B.
aus der Länge oder dem Gewicht der \textit{Items} und den Eigenschaften der \textit{Stacks}. Es gibt allerdings auch \textit{Items} mit speziellen Anforderungen, z.B. Kühlcontainer, die eine Energiequelle benötigen. Solche \textit{Items} können nur \textit{Stacks} mit entsprechender Konfiguration zugewiesen werden. Tendenziell sind dabei mehr \textit{Item}-\textit{Stack}-Zuweisungen erlaubt als verboten. Diese \textit{Placement Constraints} werden allerdings nicht direkt implementiert, sondern indirekt über hohe Kostenwerte.

Dies hat den Vorteil, dass die Placement Constraints zunächst nur \textquote{Weak Constraints} sind, d.h. es wird auch
dann eine Lösung gefunden, wenn gegen diese Nebenbedingungen verstoßen wird. Eine solche Lösung wird allerdings nur dann generiert,
wenn keine Lösung existiert, die sämtliche Placement Constraints respektiert.
Anschließend kann entschieden werden, ob solche Lösungen als zulässig gelten, oder, ob die Placement Constraints trotzdem
als \textquote{Hard Constraints} betrachtet und solche Lösungen dementsprechend unzulässig sind. Diese Art der Implementation ist sehr flexibel.

Der wesentliche Grund der Entscheidung für diese Art der Implementation ist allerdings eher pragmatischer Natur, denn der in den konstruktiven Heuristiken, die in Kapitel \ref{sec:constructive_heuristics} vorgestellt werden, verwendete Algorithmus zur Berechnung eines Minimum-Weight-Perfect-Matchings, erwartet einen vollständig bipartiten Graphen als Eingabe. Dies bedeutet, dass jedes Item zunächst mit jedem Stack kompatibel sein muss. Da die Placement Constraints genau dies jedoch verhindern, ist es sinnvoll, diese, wie im Folgenden beschrieben, indirekt über hohe Kostenwerte umzusetzen.

Zunächst werden die \textit{Placement Constraints} in einer Binärmatrix $T = (t_{iq})_{n \times m}$ kodiert, wobei:\newline
\[
    t_{iq} =
\begin{cases}
    1, & \text{wenn \textit{Item} $i$ in \textit{Stack} $q$ platziert werden darf }\\
    0, & \text{sonst}
\end{cases}
\]
Diese Matrix wird jedoch nicht direkt verwendet, um die Restriktionen zu implementieren. Stattdessen wird
die Transportkosten-Matrix $C = (c_{iq})_{n \times m}$, die in Abschnitt \ref{sec:transport_costs} eingeführt wurde, nun wie folgt erweitert.
\[
    c_{iq} =
\begin{cases}
    d_{man}(O_i, F_q), & \text{wenn $t_{iq} = 1$}\\
    \infty, & \text{sonst}
\end{cases}
\]
Der Eintrag an der Stelle $c_{iq}$ enthält also nur noch dann die tatsächlichen Transportkosten, wenn die
entsprechende \textit{Item}-\textit{Stack}-Zuweisung basierend auf den \textit{Placement Constraints} erlaubt ist und sonst $\infty$.

Die \textit{Placement Constraints} gelten als verletzt, wenn eine Lösung eine \textit{Item}-\textit{Stack}-Zuweisung der Kosten $\infty$ enthält.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Problemstellungen}
\label{sec:problem_settings}

In diesem Kapitel werden konkret die Problemstellungen eingeführt, die im Folgenden heuristisch gelöst werden.
Es werden die \textit{Stack}-Kapazitäten $b=2, b=3 $ und $ b=4$ betrachtet, die besonders in Szenarien aus der Praxis, in denen
es darum geht, Container zu stapeln, von Interesse sind.

\subsection{Komplexität}
\label{sec:complexity}

Wie \cite{Bruns2015} zeigte, handelt es sich bei dem Zulässigkeitsproblem mit einer \textit{Stack}-Kapazität von $b=3$ und gegebenen transitiven \textit{Stacking Constraints} $s_{ij}$ um ein stark NP-vollständiges Problem. Erst kürzlich wurde außerdem gezeigt, dass auch das Problem mit einer \textit{Stack}-Kapazität von $b=2$ mit gegebenen transitiven \textit{Stacking Constraints} $s_{ij}$ und \textit{Placement Constraints} $t_{iq}$ NP-vollständig ist. Diese Erkenntnis wurde allerdings noch nicht veröffentlicht. Somit sind auch die entsprechenden Stacking-Probleme, bei denen zusätzlich die Transportkosten minimiert werden, NP-vollständig. Für eben diese Probleme werden in dieser Arbeit heuristische Lösungsansätze präsentiert.

\subsection{Instanzgrößen}
\label{sec:instance_sizes}

Zu Testzwecken werden unterschiedlich große Instanzen von Stacking-Problemen generiert. Die Größe einer
Instanz bezieht sich dabei stets auf die Anzahl der betrachteten Items. Die Testinstanzen werden
in drei Kategorien unterteilt:
\begin{itemize}
  \item klein (\textbf{s}) ($\leq 100$ Items)
  \item mittelgroß (\textbf{m}) ($\approx 300$ Items)
  \item groß (\textbf{l}) ($\approx 500$ Items)\newline
\end{itemize}
Dies scheinen auch in der Literatur Größenordnungen zu sein, in dem sich praktisch motivierte Stacking-Probleme
typischerweise bewegen. \cite{Le2016}

\subsection{Zielfunktion}
\label{sec:objective}

Das Ziel, welches im Folgenden für sämtliche Problemstellungen angestrebt wird, ist eine möglichst günstige Einlagerung
sämtlicher \textit{Items}, d.h. die Zielfunktion entspricht der Minimierung der Transportkosten.
Dabei haben Zulässigkeit und geringe Laufzeit Priorität.
Eine Lösung wird dann als zulässig betrachtet, wenn sämtliche \textit{Items} unter Berücksichtigung der \textit{Stacking}- und \textit{Placement-Constraints} sowie der \textit{Stack}-Kapazität, eingelagert wurden.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Testdaten-Generierung}
\label{sec:test_data}

Um die entwickelten Lösungsverfahren testen und vergleichen zu können, mussten Test-Instanzen generiert werden,
die im Idealfall nicht allzu weit von der Realität entfernt sein sollten.
Pro Konfiguration werden 20 Instanzen generiert, um eine Vergleichbarkeit zu ermöglichen.
Die Anzahl der \textit{Items} $n$ sowie die \textit{Stack}-Kapazität $b$ wird stets spezifiziert und in der Berechnung der Anzahl
der zur Verfügung stehenden \textit{Stacks} $m$ verwendet. Es gilt $m$ = $\ceil{n / b}$ + $20 \%$.\newline
Bei einer \textit{Stack}anzahl von $m$ = $\ceil{n / b}$ gäbe es überhaupt keinen Spielraum bei der \textit{Item}platzierung. Aufgrund der in Abschnitt \ref{sec:constraints} geschilderten Nebenbedingungen wären die meisten Instanzen dann jedoch nicht lösbar. Daher wurde ein Spielraum
von $20 \%$ definiert, der durchaus gering ist und in weiteren Betrachtungen erhöht werden könnte.

\textbf{Stacking-Constraint-Generierung}\newline

Es wurden zwei Varianten der \textit{Stacking-Constraint}-Generierung implementiert, die jeweils spezifische Vor- und Nachteile aufweisen.

\textbf{Variante 1}\newline
Die \textit{Stacking-Constraint}-Matrix $S$ wird anhand einer definierten Wahrscheinlichkeit mit $1$- bzw. $0$-Einträgen gefüllt.
Anschließend werden die $1$-Einträge, die aus Transitivität folgen, ergänzt.

\textbf{Variante 2}\newline
Für alle $n$ \textit{Items} wird eine zufällige Länge und Breite generiert. \textit{Item} $i$ kann auf \textit{Item} $j$ platziert werden,
wenn für dessen Länge $l_i$ und Breite $w_i$ gilt $l_i \leq l_j$ und $w_i \leq w_j$.
Zwei \textit{Items} $i, j$ sind in beide Richtungen stackbar, wenn $l_i = l_j$ und $w_i = w_j$ gilt.

Variante 2 scheint realitätsnäher zu sein und wird deshalb zunächst bevorzugt. Aufgrund der Tatsache, dass Variante 2 jedoch stets
zu einem Anteil von $1$-Einträgen in der Matrix von ca. $25\%$ führt und dieser mit Variante 1 sehr gut konfigurierbar ist, wird Variante 1 nicht vollständig verworfen. (TODO: Grund ergänzen...)

Bei den Placement-Constraints sind in den betrachteten Tests $70\%$ der \textit{Item}-\textit{Stack}-Zuweisungen erlaubt.
Zur Transportkostenberechnung wird wie in Abschnitt \ref{sec:transport_costs} erläutert, die Manhattan-Metrik verwendet. Dazu sind
entsprechend die \textit{Item}- und \textit{Stack}positionen als $x$- und $y$-Koordinaten gegeben. Auch die entsprechenden Längen und Breiten sowie die Distanz zwischen \textit{Storage-Area} und den Fahrzeug-Lanes ist jeweils gegeben.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{MIP-Formulierungen}
\label{sec:mip_formulations}

In diesem Kapitel werden MIP-Formulierungen eingeführt, die zum experimentellen Vergleich genutzt werden.
Diese werden verwendet, um die optimalen Zielfunktionswerte der Test-Instanzen zu ermitteln und somit eine Grundlage zu schaffen, mit der die Qualität der von den Heuristiken generierten Lösungen beurteilt werden kann. Des Weiteren geht es auch um einen Vergleich der im Folgenden vorgestellten MIP-Formulierungen untereinander. Zunächst wird in Abschnitt \ref{sec:mip_definition} kurz die Idee des MIP im Allgemeinen
eingeführt, um dann im Anschluss in den Abschnitten \ref{sec:bin_packing_formulation} und \ref{sec:three_idx_formulation} die beiden in dieser Arbeit betrachteten MIP-Formulierungen im Detail vorzustellen.

\subsection{Mixed Integer Linear Programming (MIP)}
\label{sec:mip_definition}

Viele kombinatorische Optimierungsprobleme lassen sich als lineare Programme formulieren, die sich dadurch
auszeichnen, dass die Zielfunktion eine lineare Funktion in Abhängigkeit von den Entscheidungsvariablen ist
und alle Nebenbedingungen in Form von linearen Gleichungen und Ungleichungen vorliegen. Für diese Probleme gibt es mit dem Simplexverfahren ein sehr effizientes Lösungsverfahren.\cite{Knust2017}

Ein gemischt-ganzzahliges lineares Programm (MIP) ist ein lineares Programm, welches kontinuierliche und ganzzahligen Variablen
enthält. Im Gegensatz zur kontinuierlichen Variante ist die Lösung von ganzzahligen linearen Programmen NP-schwer.
Während sogar sehr große kontinuierliche lineare Programme durch kommerzielle Solver in weniegn Minuten gelöst werden können, gilt dies nicht für ganzzahlige lineare Programme. Diese können nur mit deutlich zeitaufwändigeren Algorithmen wie Branch \& Bound gelöst werden.\cite{Brucker2006}

In dieser Arbeit wird das Java-Interface von CPLEX, einem Solver für lineare Optimierungsprobleme verwendet,
um die MIP-Formulierungen, die in Abschnitt \ref{sec:bin_packing_formulation} und Abschnitt \ref{sec:three_idx_formulation} vorgestellt werden,
zu lösen. Es handelt sich dabei um eine unter anderem auf dem Simplexverfahren basierende Implementation von IBM. \cite{CPLEX2015}

\subsection{Bin-Packing-Formulierung}
\label{sec:bin_packing_formulation}

Die Bin-Packing-Formulierung orientiert sich dem Namen nach am klassichen \textsc{Bin-Packing} Problem, bei dem es darum geht,
eine Menge von Objekten so auf eine Menge von Behältern zu verteilen, dass die Behälterkapazitäten eingehalten werden.
Dies beschreibt auch direkt den Ansatz der Bin-Packing-Formulierung. Die Stacks werden als Behälter betrachtet und die Items als Objekte,
die diesen Behältern zugeordnet werden, wobei die Stack- bzw. Behälterkapazität jeweils eingehalten wird. Im Unterschied zum klassischen \textsc{Bin-Packing} müssen zusätzlich die Stacking- und Placement-Constraints berücksichtigt werden.

$G = (I, A)$ sei ein transitiver Stacking-Constraint-Graph, bei dem eine Kante $i \rightarrow j \in A$ bedeutet, dass $i$ direkt auf $j$ gestapelt werden darf. Außerdem seien Items $I = \{1, ..., n\}$ und Stacks $Q = \{1, ..., m\}$ mit einer Kapazität von $b$ gegeben.
Bei den Variablen $x_{iq}$ handelt es sich um Binärvariablen, wobei $x_{iq} = 1$ bedeutet, dass Item $i$ Stack $q$ zugewiesen wird. $c_{iq}$ entspricht den Kosten für den Transport des Items $i$ in den Stack $q$.

\begin{gather}
\boldsymbol{min} \quad \sum_{i \in I} \sum_{q \in Q} c_{iq} x_{iq} \label{bin_packing_line_one} \\
\thinspace\thinspace \boldsymbol{s.t.} \thinspace\quad\thinspace\thinspace\thinspace\quad\thinspace \quad \sum_{q \in Q} x_{iq} = 1 \quad\quad\quad\quad\quad\quad\quad \forall i \in I \quad\quad\quad\quad\thinspace\thinspace \label{bin_packing_line_two} \\
\quad \sum_{i \in I} x_{iq} \leq b \quad\quad\quad\quad\quad\quad\quad \forall q \in Q \label{bin_packing_line_three} \\
\thinspace\thinspace\quad\quad x_{iq} + x_{jq} \leq 1 \quad\quad\thinspace\thinspace\quad\quad\quad\quad \forall \{i, j\} \notin A \label{bin_packing_line_four} \\
\thinspace\thinspace\quad\quad\quad x_{iq} \in \{0, 1\} \thinspace\thinspace\thinspace\thinspace\thinspace\thinspace\quad\quad\quad\quad\quad\quad \forall i \in I, q \in Q \thinspace \label{bin_packing_line_five}
\end{gather}

In (\ref{bin_packing_line_one}) wird die Zielfunktion definiert, die der Minimierung der Transportkosten entspricht.
Nebenbedingung (\ref{bin_packing_line_two}) fordert, dass jedes Item genau einem Stack zugewiesen wird. Die Ungleichung in (\ref{bin_packing_line_three}) entspricht der Forderung, dass die Stack-Kapazität eingehalten werden muss und (\ref{bin_packing_line_four}) entspricht schließlich der Forderung, dass alle Items, die nicht stackbar sind, nicht Teil desselben Stacks sind. Außerdem handelt es sich laut (\ref{bin_packing_line_five}), wie bereits erwähnt, bei den Variablen $x_{iq}$ um Binärvariablen.

\subsection{3-Index-Formulierung}
\label{sec:three_idx_formulation}

Die 3-Index-Formulierung enthält drei Indizes: Item, Stack und Level.
Im Gegensatz zur Bin-Packing-Formulierung, die Item-Stack-Zuweisungen vornimmt, weist die 3-Index-Formulierung einem
Item auch eine konkrete Position innerhalb eines Stacks zu, sie berücksichtigt also den Level.

Gegeben ist eine Item-Menge $I = \{1, ..., n\}$ und eine Stack-Mange $Q = \{1, ..., m\}$ mit Stacks der Kapazität $b$.
Jeder Stack enthält dementsprechend die Level $L = \{1, ..., b\}$. Die Kosten seien definiert durch die gegebene Transportkostenmatrix $C$,
in der an der Stelle $c_{iq}$ die Kosten für den Transport von Item $i$ in Stack $q$ stehen. Die Variablen $x_{iql}$ seien Binärvariablen, bei denen
$x_{iql} = 1$ bedeutet, dass Item $i$ in Stack $q$ auf Level $l$ platziert wird.

\begin{gather}
\boldsymbol{min} \quad \sum_{i \in I} \sum_{q \in Q} \sum_{l \in L} c_{iq} x_{iql} \label{three_idx_line_one} \\
\boldsymbol{s.t.} \quad \sum_{q \in Q} \sum_{l \in L} x_{iql} = 1 \quad\thinspace\thinspace\quad\quad\quad\quad \forall i \in I \thinspace\thinspace\quad\quad\quad\quad\quad\quad\quad\quad\thinspace\thinspace \label{three_idx_line_two} \\
\sum_{i \in I} x_{iql} \leq 1 \thinspace\quad\quad\quad\quad\quad\quad\quad \forall q \in Q, l \in L \thinspace\thinspace\thinspace\thinspace\quad\quad\quad\thinspace \label{three_idx_line_three} \\
\sum_{j \in I | i \rightarrow j} x_{jq(l-1)} - x_{iql} \geq 0 \thinspace\quad\quad \forall i \in I, q \in Q, l \in L \textbackslash \{1\}
\label{three_idx_line_four} \\
\quad\quad x_{iql} \in \{0, 1\} \quad\quad\quad\quad\quad\quad\quad \forall i \in I, q \in Q, l \in L \quad\thinspace\thinspace\thinspace\thinspace\thinspace \label{three_idx_line_five}
\end{gather}

In (\ref{three_idx_line_one}) wird die Zielfunktion definiert, die erneut die Summe der Kosten sämtlicher Item-Zuweisungen minimiert.
Nebenbedingung (\ref{three_idx_line_two}) fordert, dass sich jedes Item in genau einem Stack an genau einer Position (Level) befinden muss.
Anschließend wird in (\ref{three_idx_line_three}) gefordert, dass sich an jeder Position in jedem Stack höchstens ein Item befindet und
(\ref{three_idx_line_four}) formuliert die Einschränkung, dass alle Items, die sich oberhalb des Ground-Levels befinden, ein Item unter sich haben,
welches unter ihnen liegen darf. Schließlich wird in (\ref{three_idx_line_five}) festgehalten, dass es sich bei den $x_{iql}$ um Binärvariablen handelt.

Beide Formulierungen vollziehen Item-Stack-Zuweisungen und minimieren dabei die Transportkosten.
Die Bin-Packing-Formulierung nimmt dabei lediglich Item-Stack-Zuweisungen vor, während die 3-Index-Formulierung die
Items konkreten Positionen innerhalb der Stacks zuweist. Dabei ist allerdings auch bei der Bin-Packing-Formulierung
sichergestellt, dass eine Item-Stack-Zuweisung nur dann vorgenommen wird, wenn die Items innerhalb des Stacks anschließend
der Art umsortiert werden können, dass sie den Stacking Constraints entsprechen. Diese Tatsache ergibt sich aus Nebenbedingung (\ref{bin_packing_line_four}), die fordert, dass Items sich nur dann im selben Stack befinden, wenn sie in mindestens einer Richtung stackbar sind.
Da die Stacking Constraints außerdem transitiv sind, ist sichergestellt, dass die Reihenfolge innerhalb der Stacks stets so korrigiert
werden kann, dass eine valide Lösung dabei herauskommt.

Die 3-Index-Formulierung liefert also direkt eine valide Lösung, während die Item-Stack-Zuweisungen, die die Bin-Packing-Formulierung liefert,
zunächst noch sortiert werden müssen, damit sie eine valide Lösung ergeben. Dies kann durch den simplen Algorithmus (\ref{alg:algo1}) erreicht werden.
Wie bereits erwähnt, ist garantiert, dass eine Lösung, die die Stacking Constraints respektiert, generiert werden kann.

\begin{algorithm}
\fontsize{10pt}{10pt}

\SetAlgoLined

  \ForEach{stack in storageArea}{

    somethingChanged = true\;

    \While{somethingChanged}{

      somethingChanged = false\;

      \For{position = 0; position < stack.capacity - 1; position++}{
          \BlankLine\BlankLine
          \uIf{stack[position].\Call{isOccupied()}{} \&\& stack[position + 1].\Call{isOccupied()}{{}}}{
            \uIf{itemAt(stack[position]).\Call{isStackableOn}{itemAt(stack[position + 1])}}{

                \Call{exchangeItems}{stack[position], stack[position + 1]}\;
                somethingChanged = true\;
                break\;
            }
          }
      }
    }
  }

\caption{Korrektur der Item Reihenfolge innerhalb der Stacks.}
\label{alg:algo1}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Konstruktive Heuristiken}
\label{sec:constructive_heuristics}

In diesem Abschnitt werden die entwickelten konstruktiven Heuristiken vorgestellt.
Zunächst werden drei wichtige Konzepte eingeführt, die in den Heuristiken Verwendung finden.
In \ref{sec:digression_mcm} Maximum-Cardinality-Matchings,
in \ref{sec:digression_mwpm} Minimum-Weight-Perfect-Matchings und in \ref{sec:digression_bipartite_graph}
bipartite Graphen. Anschließend geht es in \ref{sec:two_cap_heuristic} um die konstruktive Heuristik für eine Stack-Kapazität
von $b=2$ und darauffolgend in \ref{sec:solver_comp_b=2} um einen Vergleich der Solver für eben diese Stack-Kapazität.
In \ref{sec:three_cap_heuristic} geht es dann um die konstruktive Heuristik für eine Stack-Kapazität von $b=3$, auf
die erneut ein Vergleich der entsprechenden Solver in \ref{sec:solver_comp_b=3} folgt.

\subsection{Exkurs: Maximum-Cardinality-Matching (MCM)}
\label{sec:digression_mcm}

Gegeben sei ein ungerichteter Graph $G = (V, E)$. Eine Menge $M \subseteq E$ heißt Matching,
wenn keine zwei Kanten aus $M$ einen Knoten gemeinsam haben. Falls $M$ als Menge eine maximale Kardinalität unter
allen Matchings von $G$ hat, wird dies als Maximum-Cardinality-Matching bezeichnet. \cite{WikiMatching}
Es kann mehrere unterschiedliche MCMs in einem Graphen geben.
In Abb. \ref{fig:mcm_examples} werden beispielhaft zwei MCMs dargestellt.
\begin{figure}[H]
  \begin{subfigure}[b]{0.4\textwidth}
  \centering
    \begin{tikzpicture}[scale=0.45, transform shape, node distance=2cm]
    \node[state] (A) {};
    \node[state] (B) [above right of=A] {};
    \node[state] (C) [below left of=A] {};
    \node[state] (D) [below right of=C] {};
    \node[state] (F) [below right of=B] {};
    \node[state] (E) [below of=F] {};

    \path (A) edge [red] node {} (B)
          (A) edge node {} (C)
          (A) edge node {} (D)
          (A) edge node {} (E)
          (A) edge node {} (F)
          (C) edge [red] node {} (D);
  \end{tikzpicture}
  \caption{\textsc{$|MCM| = 2$}}
  \label{fig:mcm1}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.4\textwidth}
  \centering
    \begin{tikzpicture}[scale=0.45, transform shape, node distance=2cm]
    \node[state] (A) {};
    \node[state] (B) [right of=A] {};
    \node[state] (C) [right of=B] {};
    \node[state] (D) [below left of=A] {};
    \node[state] (E) [below right of=D] {};
    \node[state] (F) [right of=E] {};

    \path (A) edge node {} (B)
          (B) edge [red] node {} (C)
          (B) edge node {} (F)
          (A) edge node {} (E)
          (E) edge [red] node {} (F)
          (A) edge [red] node {} (D)
          (D) edge node {} (E);
  \end{tikzpicture}
    \caption{\textsc{$|MCM| = 3$}}
    \label{fig:mcm_2}
  \end{subfigure}
  \caption{\textsc{Zwei Beispiele für MCMs (dargestellt in rot).}}
  \label{fig:mcm_examples}
\end{figure}

\subsection{Exkurs: Minimum-Weight-Perfect-Matching}
\label{sec:digression_mwpm}

Zunächst einmal ist es wichtig, zu erwähnen, dass ein Perfect-Matching nur für Graphen mit einer geraden Anzahl an Knoten möglich ist.
Ein Perfect-Matching ist ein Matching, welches sämtliche Knoten des Graphen matcht.
D.h. jeder Knoten des Graphen ist inzident zu genau einer Kante des Matchings (vgl. Abb. \ref{fig:perfect_matching}).
Ein Minimum-Weight-Perfect-Matching ist nun ein günstigstes Perfect-Matching basierend auf den Kantenkosten.
\begin{figure}[H]
\centering
\begin{tikzpicture}[-, scale=0.40, transform shape, node distance=3cm]
    \node[state] (A) {};
    \node[state] (B) [above right of=A] {};
    \node[state] (C) [below right of=A] {};
    \node[state] (D) [right of=B] {};
    \node[state] (E) [right of=D] {};
    \node[state] (F) [right of=C] {};

    \path (A) edge [red] node {} (B)
          (A) edge node {} (C)
          (B) edge node {} (D)
          (B) edge node {} (C)
          (D) edge [red] node {} (E)
          (D) edge node {} (F)
          (C) edge [red] node {} (F);
\end{tikzpicture}
\caption{\textsc{Beispiel für ein Perfect-Matching (rot).}}
\label{fig:perfect_matching}
\end{figure}

\subsection{Exkurs: Bipartiter Graph}
\label{sec:digression_bipartite_graph}

Ein Graph $G = (V, E)$ heißt bipartit (vgl. Abb. \ref{fig:bipartite_graph}), wenn die Knotenmenge in zwei disjunkte Teilmengen zerfällt
$(V = S \cup T$ mit $S \cap T = \emptyset$), sodass jede Kante einen Knoten aus $S$ mit einem Knoten aus $T$ verbindet. \cite{HochschuleDarmstadt}\newline
Es lassen sich folgende Äquivalenzen festhalten:
\begin{itemize}
  \item $G$ bipartit $\iff$ $G$ 2-färbbar
  \item $G$ bipartit $\iff$ keine Kreise ungerader Länge in $G$
\end{itemize}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.50, transform shape, node distance=3cm]
  \node[state] [green] (A) {};
  \node[state] [red] (B) [above right of=A] {};
  \node[state] [green] (C) [below right of=B] {};
  \node[state] [red] (D) [below of=B] {};
  \node[state] [red] (E) [below of=A] {};
  \node[state] [green] (F) [right of=E] {};

  \path (A) edge node {} (B)
        (B) edge node {} (C)
        (C) edge node {} (D)
        (A) edge node {} (D)
        (A) edge node {} (E)
        (E) edge node {} (F)
        (D) edge node {} (F);

\end{tikzpicture}
\caption{\textsc{Bipartiter Graph.}}
\label{fig:bipartite_graph}
\end{figure}

\subsection{Konstruktive Heuristik ($b = 2$)}
\label{sec:two_cap_heuristic}

In diesem Abschnitt wird die konstruktive Heuristik zur Lösung von Stacking-Problemen mit Stacks der Kapazität $b=2$
vorgestellt.

Zunächst wird ein Stacking-Constraint-Graph $G = (V, E)$ generiert, welcher die Items als Knoten enthält, d.h. $V = I$. Dieser Graph
enthält eine Kante $\{i, j\}$ zwischen zwei Knoten, wenn die entsprechenden Items $i, j \in I$ in mindestens einer Richtung stackbar sind, d.h.
wenn $s_{ij} + s_{ji} \geq 1$.

Berechnet man nun ein \textsc{MCM} in $G$ und interpretiert dessen Kanten als Item-Paare, so bekommt man die größtmögliche Anzahl
von Item-Paaren. Im Grunde kann man nun bereits jede Kante des \textsc{MCM} als Stack betrachten, welcher die beiden Knoten, die durch
die Kante verbunden werden, als Items enthält. Des Weiteren werden die Items, die nicht gematcht werden, auf dem Ground-Level platziert.
Insgesamt werden auf diese Weise so wenig Stacks wie möglich verwendet. Eine zulässige Lösung mit maximal $m$ Stacks existiert nur dann,
wenn die Anzahl der Kanten im Matching plus der Anzahl der nicht gematchten Knoten nicht größer ist als $m$. Da die Anzahl der Knoten $n$ beträgt, kann ein \textsc{MCM} in der Laufzeit $O(n^{2.5})$ berechnet werden, wie Even und Kariv bereits 1975 zeigte.

Dies entspricht dem Vorgehen aus dem Beweis zu Theorem 1 aus dem Paper "Complexity Results for Storage Loading Problems with Stacking Constraints",
welches 2015 von Bruns et al. veröffentlicht wurde.

Augrund der Placement Constraints kann allerdings nicht jedes Item in jedem Stack platziert werden, weshalb noch die bestmögliche Zuweisung von
Items- und Item-Paaren zu Stacks gefunden werden muss. Diese entspricht idealerweise einer Zuweisung, in der sämtliche Items einem Stack zugeordnet werden. Dafür wird ein bipartiter Graph $G_1 = (V_1 \cup V_2, E)$ generiert, wobei die Partition $V_1$ den Items, bestehend aus Item-Paaren und Unmatched Items, entspricht und $V_2$ den zur Verfügung stehenden Stacks.

Für alle $i \in V_1$ und $q \in V_2$ wird nun eine Kante $\{i, q\}$ eingeführt. Das Gewicht $c_{iq}$ dieser Kante ist definiert als die Kosten
des Transports von Item $i$ von seiner Originalposition $O_i$ zum Stack $q$.

Auf diesem Graph wird wiederum ein \textsc{MWPM} berechnet,
bei dem die Kanten als Stackzuweisungen interpretiert werden. Abschließend muss ggf. die Reihenfolge innerhalb der Stacks angepasst werden,
da für die Item-Paare bisher nur sichergestellt ist, dass sie kompatibel sind, die Reihenfolge wurde noch nicht festgelegt.

\textbf{Beispiel}

$I := \{0, 1, 2, 3, 4, 5, 6\} \quad\quad\quad b := 2 \quad\quad\quad m := 4$

Zunächst wird der in Abb. \ref{fig:stacking_const_graph_example_b=2_a} dargestellte Stacking-Constraint-Graph für die gegebenen Items generiert.
Darauf wird das in \ref{fig:stacking_const_graph_example_b=2_b} in grün dargestellte \textsc{MCM} berechnet, wobei Item 0 unmatched ist.
\begin{figure}[H]
  \centering
    \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \begin{tikzpicture}[scale=0.75, transform shape, node distance=3cm]
        \node[state] (G) [thick] {$\boldsymbol{6}$};
        \node[state] (B) [thick, above left of=G] {$\boldsymbol{1}$};
        \node[state] (C) [thick, above right of=G] {$\boldsymbol{2}$};
        \node[state] (E) [thick, below right of=G] {$\boldsymbol{4}$};
        \node[state] (F) [thick, below left of=G] {$\boldsymbol{5}$};
        \node[state] (A) [thick, below left of=B] {$\boldsymbol{0}$};
        \node[state] (D) [thick, below right of=C] {$\boldsymbol{3}$};

        \path (B) edge [thick] node {} (C)
              (B) edge [thick] node {} (F)
              (B) edge [thick] node {} (G)
              (C) edge [thick, bend right = 75, distance=5cm] node {} (F)
              (C) edge [thick] node {} (E)
              (C) edge [thick] node {} (D)
              (C) edge [thick] node {} (G)
              (F) edge [thick] node {} (G)
              (F) edge [thick] node {} (E)
              (E) edge [thick] node {} (G);
    \end{tikzpicture}
    \caption{\textsc{Stacking-Constraint-Graph}}
    \label{fig:stacking_const_graph_example_b=2_a}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \begin{tikzpicture}[scale=0.75, transform shape, node distance=3cm]
        \node[state] (G) [thick] {$\boldsymbol{\textcolor{mygreen}{6}}$};
        \node[state] (B) [thick, above left of=G] {$\boldsymbol{\textcolor{mygreen}{1}}$};
        \node[state] (C) [thick, above right of=G] {$\boldsymbol{\textcolor{mygreen}{2}}$};
        \node[state] (E) [thick, below right of=G] {$\boldsymbol{\textcolor{mygreen}{4}}$};
        \node[state] (F) [thick, below left of=G] {$\boldsymbol{\textcolor{mygreen}{5}}$};
        \node[state] (A) [thick, below left of=B] {$\boldsymbol{\textcolor{red}{0}}$};
        \node[state] (D) [thick, below right of=C] {$\boldsymbol{\textcolor{mygreen}{3}}$};

        \path (B) edge [thick] node {} (C)
              (B) edge [thick] node {} (F)
              (B) edge [thick, mygreen] node {} (G)
              (C) edge [thick, bend right = 75, distance=5cm] node {} (F)
              (C) edge [thick] node {} (E)
              (C) edge [thick, mygreen] node {} (D)
              (C) edge [thick] node {} (G)
              (F) edge [thick] node {} (G)
              (F) edge [thick, mygreen] node {} (E)
              (E) edge [thick] node {} (G);
    \end{tikzpicture}
    \caption{\textsc{MCM (Item $0$ unmatched)}}
    \label{fig:stacking_const_graph_example_b=2_b}
    \end{subfigure}
    \caption{}
    \label{fig:stacking_const_graph_example_b=2}
\end{figure}

Die Kanten des in \ref{fig:stacking_const_graph_example_b=2_b} dargestellten \textsc{MCM} werden nun wie in \ref{fig:item_pairs}
abgebildet, als Item-Paare interpretiert.

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.7, transform shape, node distance=3cm]
        \node[state] (A) [thick] {\textcolor{mygreen}{$\boldsymbol{1, 6}$}};
        \node[state] (B) [thick, right of=A] {\textcolor{mygreen}{$\boldsymbol{2, 3}$}};
        \node[state] (C) [thick, right of=B] {\textcolor{mygreen}{$\boldsymbol{4, 5}$}};
        \node[state] (D) [thick, right of=C] {\textcolor{red}{$\boldsymbol{0}$}};
        \path ;
  \end{tikzpicture}
  \caption{\textsc{Resultierende Item-Paare.}}
  \label{fig:item_pairs}
\end{figure}

Da nun noch die Zuweisung der Item-Paare und Unmatched Items zu Stacks fehlt, wird der vollständig bipartite Graph
in Abb. \ref{fig:bipartite_graph} generiert. In Abb. \ref{fig:mwpm} sieht man das darauf berechnete \textsc{MWPM},
welches wie in \ref{fig:stacking_solution} dargestellt, als zulässige Stack-Zuweisung interpretiert werden kann.

\begin{figure}[H]
\begin{subfigure}[b]{0.45\textwidth}
\centering
\begin{tikzpicture}[scale=0.7, transform shape, node distance=1.5cm]
        \node[state] (A) [thick] {$\boldsymbol{1, 6}$};
        \node[state] (B) [thick, below of=A] {$\boldsymbol{2, 3}$};
        \node[state] (C) [thick, below of=B] {$\boldsymbol{4, 5}$};
        \node[state] (D) [thick, below of=C] {$\boldsymbol{0}$};

        \node[state] (F) [thick, right = 4cm of A] {$\boldsymbol{S_1}$};
        \node[state] (G) [thick, right = 4cm of B] {$\boldsymbol{S_2}$};
        \node[state] (H) [thick, right = 4cm of C] {$\boldsymbol{S_3}$};
        \node[state] (I) [thick, right = 4cm of D] {$\boldsymbol{S_4}$};

        \path
          % from (1,6) to all stacks
          (A) edge [thick] node {} (F)
          (A) edge [thick] node {} (G)
          (A) edge [thick] node {} (H)
          (A) edge [thick] node {} (I)

          % from (2,3) to all stacks
          (B) edge [thick] node {} (F)
          (B) edge [thick] node {} (G)
          (B) edge [thick] node {} (H)
          (B) edge [thick] node {} (I)

          % from (4,5) to all stacks
          (C) edge [thick] node {} (F)
          (C) edge [thick] node {} (G)
          (C) edge [thick] node {} (H)
          (C) edge [thick] node {} (I)

          % from 0 to all stacks
          (D) edge [thick] node {} (F)
          (D) edge [thick] node {} (G)
          (D) edge [thick] node {} (H)
          (D) edge [thick] node {} (I);
  \end{tikzpicture}
  \caption{\textsc{vollständig bipartit}}
  \label{fig:bipartite_graph}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.45\textwidth}
\centering
\begin{tikzpicture}[scale=0.7, transform shape, node distance=1.5cm]
        \node[state] (A) [thick] {$\boldsymbol{1, 6}$};
        \node[state] (B) [thick, below of=A] {$\boldsymbol{2, 3}$};
        \node[state] (C) [thick, below of=B] {$\boldsymbol{4, 5}$};
        \node[state] (D) [thick, below of=C] {$\boldsymbol{0}$};

        \node[state] (F) [thick, right = 4cm of A] {$\boldsymbol{S_1}$};
        \node[state] (G) [thick, right = 4cm of B] {$\boldsymbol{S_2}$};
        \node[state] (H) [thick, right = 4cm of C] {$\boldsymbol{S_3}$};
        \node[state] (I) [thick, right = 4cm of D] {$\boldsymbol{S_4}$};

        \path
          (A) edge [thick] node {} (I)
          (B) edge [thick] node {} (H)
          (C) edge [thick] node {} (G)
          (D) edge [thick] node {} (F);
  \end{tikzpicture}
  \caption{\textsc{MWPM}}
  \label{fig:mwpm}
\end{subfigure}
\caption{}
\end{figure}

\begin{figure}[H]
  \centering
  \resizebox{0.4\textwidth}{!}{
    \begin{tabular}{c|c|c|c|c|}
    \cline{2-5}
    $\boldsymbol{L_2}$ & $$ & $5$ & $3$ & $6$ \\ \cline{2-5}
    $\boldsymbol{L_1}$ & $0$ & $4$ & $2$ & $1$ \\ \cline{2-5}
    \multicolumn{1}{c}{} & \multicolumn{1}{c}{$\boldsymbol{S_1}$} & \multicolumn{1}{c}{$\boldsymbol{S_2}$}
    & \multicolumn{1}{c}{$\boldsymbol{S_3}$} & \multicolumn{1}{c}{$\boldsymbol{S_4}$} \\
    \end{tabular}}
    \caption{\textsc{Zulässige Zuweisungen (ggf. Item-Reihenfolge korrigieren)}}
    \label{fig:stacking_solution}
\end{figure}

Zuletzt muss ggf. noch die Reihenfolge innerhalb der Stacks angepasst werden, da es sich bisher nur um zulässige Zuweisungen handelt.
Da jedoch sichergestellt ist, dass die Items und Item-Paare kompatibel sind, ist dies trivial durch Anwendung des Algorithmus
\ref{alg:algo1} möglich.

\subsection{Vergleich der $b = 2$ Solver}
\label{sec:solver_comp_b=2}

In diesem Kapitel werden die verschiedenen Solver für Instanzen mit einer Stack-Kapazität von $b=2$ miteinander verglichen.
Die relevanten Kategorien sind dabei der im Folgenden als Instance-Coverage bezeichnete prozentuale Anteil an gelösten Instanzen,
die Laufzeit und die prozentuale Abweichung vom Optimum.

Die MIP-Formulierungen wurden mit dem Java-Interface von CPLEX 12.8.0 implementiert.
Dabei wurde CPLEX über den Parameter \textsc{CPX\_MIPEMPHASIS\_FEASIBILITY} so konfiguriert, dass die Zulässigkeit
Priorität vor der Optimalität hat.\cite{IBM_DOC}

Die in dieser Arbeit entwickelten Heuristiken wurden ebenfalls in der Programmiersprache Java implementiert.

Sämtliche Experimente wurden auf einem Rechner mit Intel Core i5-8500 (6x 3.00GHz) Prozessor und 32 GB RAM durchgeführt.

\pagebreak

\textbf{Kleine Instanzen (s)}

In den Diagrammen in Abb. \ref{fig:instance_cov_b=2_s} ist jeweils die Instance-Coverage der einzelnen Solver dargestellt.
In \ref{fig:instance_cov_b=2_s_a} handelt es sich um den prozentualen Anteil an gelösten Instanzen pro Solver bei einem Zeitlimit
von $1s$ pro Instanz, in \ref{fig:instance_cov_b=2_s_b} bei einem Zeitlimit von $3s$ und in \ref{fig:instance_cov_b=2_s_c} $5s$.

Wie bereits in Kapitel \ref{sec:test_data} erläutert, wurden jeweils 20 Instanzen pro Konfiguration zu Grunde gelegt.

Die wesentliche Erkenntnis aus Abb. \ref{fig:instance_cov_b=2_s} ist, dass sämtliche Instanzen bereits bei einem Zeitlimit von $5s$
von allen Solvern gelöst werden, was darauf hindeutet, dass der Bedarf für eine Laufzeitverbesserung durch eine Heuristik auch
aus praktischer Perspektive hier gering sein sollte.

\begin{figure}[H]
\centering

\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=2_s_1s.png}
\caption{\textsc{Zeitlimit 1s}}
\label{fig:instance_cov_b=2_s_a}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=2_s_3s.png}
\caption{\textsc{Zeitlimit 3s}}
\label{fig:instance_cov_b=2_s_b}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=2_s_5s.png}
\caption{\textsc{Zeitlimit 5s}}
\label{fig:instance_cov_b=2_s_c}
\end{subfigure}

\caption{\textsc{Instance-Coverage der $b=2$ Solver (s)}}
\label{fig:instance_cov_b=2_s}
\end{figure}

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.4\textwidth}
\centering
\includegraphics[width=1.3\textwidth]{img/solver_instance_time_b=2_s_5s.png}
\caption{\textsc{Laufzeiten bei 5s Zeitlimit}}
\label{fig:b=2_s_runtimes}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.4\textwidth}
\centering
\includegraphics[width=1.3\textwidth]{img/solver_instance_cost_b=2_s_5s.png}
\caption{\textsc{Kosten bei 5s Zeitlimit}}
\label{fig:b=2_s_costs}
\end{subfigure}
\caption{}
\end{figure}

In Abb. \ref{fig:b=2_s_runtimes} sind die Laufzeiten der Heuristiken pro Instanz bei einem Zeitlimit von $5s$ aufgetragen. Man erkennt, dass
die 3-Index-Formulierung deutlich schneller ist als die Bin-Packing-Formulierung und, dass die Heuristik beide MIP-Formulierungen noch einmal deutlich unterbietet. Aufgrund der Tatsache, dass CPLEX nur dann vor dem Zeitlimit terminiert, wenn die Instanz optimal gelöst wurde, ist klar
ersichtlich, dass die 3-Index-Formulierung sämtliche Instanzen nach etwa $1s$ optimal löst während die Bin-Packing-Formulierung in wenigen Fällen noch durch das Zeitlimit gestoppt wird.

Die exakten Ergebnisse der MIP-Formulierungen sind den Tabellen in Abb. \ref{fig:table} zu entnehmen.
\textquote{Optimal} bezeichnet den Anteil der Instanzen, die optimal gelöst wurden. Bei der \textquote{Laufzeit} handelt
es sich um die durchschnittliche Laufzeit in Sekunden und \textquote{Abweichung} gibt die durchschnittliche prozentuale Abweichung
vom Optimum an.

\begin{figure}[H]
\centering

\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $ \textcolor{red}{0 \%}$ & $ \textcolor{mygreen}{35 \%}$ \\ \hline
    \textbf{Laufzeit} & $\textcolor{red}{---}$ & \O $\thinspace \textcolor{mygreen}{0.9 s}$ \\ \hline
    \textbf{Abweichung} & $\textcolor{red}{---}$ & \O $\thinspace \textcolor{mygreen}{2.0 \%}$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $1s$}
\label{fig:res_b=2_s_a}
\end{subfigure}
% $\quad\quad\quad\quad$
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $ \textcolor{red}{10 \%}$ & $ \textcolor{mygreen}{100 \%}$ \\ \hline
    \textbf{Laufzeit} & \O $\thinspace \textcolor{red}{3.0 s}$ & \O $\thinspace \textcolor{mygreen}{1.1 s}$ \\ \hline
    \textbf{Abweichung} & \O $\thinspace \textcolor{red}{4.7 \%}$ & \O $\thinspace \textcolor{mygreen}{0.0 \%}$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $3s$}
\label{fig:res_b=2_s_b}
\end{subfigure}
% \end{figure}
% \begin{figure}[H]
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $ \textcolor{red}{90 \%}$ & $ \textcolor{mygreen}{100 \%}$ \\ \hline
    \textbf{Laufzeit} & \O $\thinspace \textcolor{red}{3.9 s}$ & \O $\thinspace \textcolor{mygreen}{1.1 s}$ \\ \hline
    \textbf{Abweichung} & \O $\thinspace \textcolor{red}{0.4 \%}$ & \O $\thinspace \textcolor{mygreen}{0.0 \%}$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $5s$}
\label{fig:res_b=2_s_c}
\end{subfigure}

\caption{}
\label{fig:table}
\end{figure}

Da die Zeitlimits aufgrund der geringen Laufzeit für die Heuristik keine Rolle spielen, kommt diese stets zum selben Ergebnis.
Sie weicht durchschnittlich um $2.0 \%$ vom Optimum ab und benötigt dafür eine Laufzeit von $0.02s$.

Da die 3-Index-Formulierung sämtliche Instanzen mit einer durchschnittlichen Laufzeit von $1.1s$ optimal löst, ist der Bedarf für
eine Laufzeitverbesserung durch eine Heuristik aus praktischer Perspektive vermutlich eher gering. Dessen ungeachtet kommt die
Heuristik mit einer sehr geringen Laufzeit zu guten Ergebnissen.

\textbf{Mittelgroße Instanzen (m)}

Interessanter wird es bereits bei den mittelgroßen Instanzen. In Abb. \ref{fig:instance_cov_b=2} ist erneut die Instance-Coverage
der einzelnen Solver dargestelllt. Man sieht, dass die Bin-Packing-Formulierung nach einer Minute noch keine Instanz gelöst hat, während die
3-Index-Formulierung dort bereits $80 \%$ der Instanzen löst. Selbst nach $10$ Minuten löst die Bin-Packing-Formulierung nur
$20 \%$ der Instanzen, 3-Index löst bei diesem Zeitlimit sämtliche Instanzen. Bei einem Zeitlimit von $20$ Minuten löst schließlich auch
die Bin-Packing sämtliche Instanzen. Die Heuristik löst in jedem Fall sämtliche Instanzen.
\begin{figure}[H]
\centering

\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=2_m_60s.png}
\caption{\textsc{Zeitlimit} $1min$}
\label{fig:instance_cov_b=2_m_a}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=2_m_600s.png}
\caption{\textsc{Zeitlimit} $10min$}
\label{fig:instance_cov_b=2_m_b}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=2_m_1200s.png}
\caption{\textsc{Zeitlimit} $20min$}
\label{fig:instance_cov_b=2_m_c}
\end{subfigure}
\caption{}
\label{fig:instance_cov_b=2}
\end{figure}

Da die Zeitlimits aufgrund der geringen Laufzeit für die Heuristik erneut keine Rolle spielen,
kommt diese stets zum selben Ergebnis. Sie weicht durchschnittlich um $0.8 \%$ vom
Optimum ab und benötigt dafür eine Laufzeit von $0.1s$. In Abb. \ref{fig:res_plots_b=2_m} sind die Laufzeiten und
Kosten der Solver bei einem Zeitlimit von $20$ Minuten dargestellt. Da die Bin-Packing- und die 3-Index-Formulierung
bei diesem Zeitlimit sämtliche Instanzen optimal lösen, kommen sie stets zum selben Kostenwert (vlg. Abb \ref{fig:b=2_m_costs}).
In Abb. \ref{fig:b=2_m_runtimes} ist gut zu erkennen, dass die Bin-Packing-Formulierung deutlich längere Laufzeiten als die 3-Index-Formulierung
und die Heurisktik benötigt, wobei die Heuristik noch einmal deutlich schneller ist. Dabei handelt es sich allerdings um die absoluten Laufeiten.
Im Wesentlichen ist der Laufzeitunterschied zwischen der Heuristik und der 3-Index-Formulierung deutlich größer, als der zwischen den beiden
MIP-Formulierungen. Zwischen der Heuristik, die durchschnittlich $0.1s$ benötigt und der 3-Index-Formulierung, die durchschnittlich $107.8s$ benötigt (vgl. Abb. \ref{fig:res_b=2_m_c}) besteht ein Faktor von $1077.0$ während zwischen den beiden MIP-Formulierungen nur ein Faktor von
$7.1$ besteht. Die absolute Darstellung ist in diesem Fall also etwas irreführend, da die Heuristik deutlich schneller ist als beide MIP-Formulierungen. Trotzdem würde man in diesem Fall aus praktischer Perspektive die 3-Index-Formulierung klar der Bin-Packing-Formulierung vorziehen, dieser Sachverhalt ist in Abb. \ref{fig:b=2_m_runtimes} gut dargestellt.

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.4\textwidth}
\centering
\includegraphics[width=1.3\textwidth]{img/solver_instance_time_b=2_m_1200s.png}
\caption{\textsc{Laufzeiten bei $20min$ Limit}}
\label{fig:b=2_m_runtimes}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.4\textwidth}
\centering
\includegraphics[width=1.3\textwidth]{img/solver_instance_cost_b=2_m_1200s.png}
\caption{\textsc{Kosten bei $20min$ Limit}}
\label{fig:b=2_m_costs}
\end{subfigure}
\caption{}
\label{fig:res_plots_b=2_m}
\end{figure}

In den Tabellen in Abb. \ref{fig:res_b=2_m} können die exakten Ergebnisse der MIP-Formulierungen nachvollzogen werden.
Wie bereits erwähnt, hat die Bin-Packing-Formulierung bei einem Zeitlimit von einer Minute keine Instanz gelöst, die 3-Index-Formulierung löst
$80 \%$ der Instanzen, allerdings nur $50 \%$ optimal (vlg. \ref{fig:res_b=2_m_a}). Die 3-Index-Formulierung benötigt dafür durchschnittlich
$55.4s$ und weicht, genau wie die Heuristik, um durchschnittlich $0.8 \%$ vom Optimum ab. Die Heuristik löst dabei allerdings sämtliche Instanzen
und benötigt nur durchschnittlich $0.1s$.

Zusammenfassend kann man sagen, dass die 3-Index-Formulierung bei den mittelgroßen Instanzen der Bin-Packing-Formulierung vorzuziehen ist,
da sie bei allen betrachteten Zeitlimits die besseren Ergebnisse erzielt und auch beim Zeitlimit von $20$ Minuten, bei dem schließlich auch die Bin-Packing-Formulierung sämtliche Instanzen optimal löst, deutlich schneller ist als diese.

Dennoch ist der Laufzeitunterschied der MIP-Formulierungen im Vergleich zur Heuristik wie bereits zuvor erwähnt, so groß, dass die Abweichung von nur durchschnittlich $0.8 \%$ in der Praxis vermutlich in den meisten Fällen in Kauf genommen werden kann, wenn sich damit derart viel Laufzeit einsparen lässt. In diesem Szenario präsentiert sich die Heuristik also als gute Alternative.

\begin{figure}[H]
% \end{figure}
% \begin{figure}[H]
% $\quad\quad\quad\quad$
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $ \textcolor{red}{0 \%}$ & $ \textcolor{mygreen}{50 \%}$ \\ \hline
    \textbf{Laufzeit} & $\textcolor{red}{----}$ & \O $\thinspace \textcolor{mygreen}{55.4 s}$ \\ \hline
    \textbf{Abweichung} & $\textcolor{red}{----}$ & \O $\thinspace \textcolor{mygreen}{0.8 \%}$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $1min$}
\label{fig:res_b=2_m_a}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $ \textcolor{red}{10 \%}$ & $ \textcolor{mygreen}{100 \%}$ \\ \hline
    \textbf{Laufzeit} & \O $\thinspace \textcolor{red}{581.6 s}$ & \O $\thinspace \textcolor{mygreen}{73.7 s}$ \\ \hline
    \textbf{Abweichung} & \O $\thinspace \textcolor{red}{0.6 \%}$ & \O $\thinspace \textcolor{mygreen}{0.0 \%}$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $10min$}
\label{fig:res_b=2_m_b}
\end{subfigure}
% \end{figure}
% \begin{figure}[H]
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $ 100 \%$ & $ 100 \%$ \\ \hline
    \textbf{Laufzeit} & \O $\thinspace 869.6 s$ & \O $\thinspace \textcolor{mygreen}{107.8 s}$ \\ \hline
    \textbf{Abweichung} & \O $\thinspace 0.0 \%$ & \O $\thinspace 0.0 \%$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $20min$}
\label{fig:res_b=2_m_c}
\end{subfigure}
\caption{}
\label{fig:res_b=2_m}
\end{figure}

\pagebreak

\textbf{Große Instanzen (l)}

In der Kategorie der großen Instanzen wurden noch einmal größere Zeitlimits von $15$, $30$ und $45$
Minuten betrachtet. In Abb. \ref{fig:instance_cov_b=2_l} fällt sofort auf, dass die Bin-Packing-Formulierung überhaupt keine Instanz löst.
Dies liegt zum einen daran, dass im betrachteten Zeitlimit tatsächlich noch keine Lösung gefunden wurde,
zum anderen aber auch daran, dass der Speicherbedarf den zur Verfügung stehenden Speicher überschritt.
TODO: Grund checken: B\&B Tree?

\begin{figure}[H]
\centering

\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=2_l_900s.png}
\caption{\textsc{Zeitlimit} $15min$}
\label{fig:instance_cov_b=2_l_a}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=2_l_1800s.png}
\caption{\textsc{Zeitlimit} $30min$}
\label{fig:instance_cov_b=2_l_b}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=2_l_2700s.png}
\caption{\textsc{Zeitlimit} $45min$}
\label{fig:instance_cov_b=2_l_c}
\end{subfigure}

\caption{}
\label{fig:instance_cov_b=2_l}
\end{figure}

In Abb. \ref{fig:res_b=2_l} sind erneut die exakten Ergebnisse der MIP-Formulierungen aufgeführt, denen man
entnehmen kann, dass die 3-Index-Formulierung mit einer durchschnittlichen Laufzeit von ca. $20$ Minuten sämtliche Instanzen
optimal löst. Die Heuristik benötigt allerdings nur durchschnittlich $0.7s$ pro Instanz und weicht auch nur um im Durchschnitt
$0.6 \%$ vom Optimalwert ab. Dieser erhebliche Laufzeitunterschied und die nur sehr geringe Abweichung vom Optimum sorgen wie auch
schon bei den mittelgroßen Instanzen dafür, dass die Heuristik in der Praxis, wenn geringe Abweichungen gestattet sind, bevorzugt wird.


\begin{figure}[H]
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $ \textcolor{red}{0 \%}$ & $ \textcolor{mygreen}{70 \%}$ \\ \hline
    \textbf{Laufzeit} & \textcolor{red}{$---$} & \O $\thinspace \textcolor{mygreen}{728.0 s}$ \\ \hline
    \textbf{Abweichung} & \textcolor{red}{$---$} & \O $\thinspace \textcolor{mygreen}{0.53 \%}$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $15min$}
\label{}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $ \textcolor{red}{0 \%}$ & $ \textcolor{mygreen}{85 \%}$ \\ \hline
    \textbf{Laufzeit} & \textcolor{red}{$---$} & \O $\thinspace \textcolor{mygreen}{977.2 s}$ \\ \hline
    \textbf{Abweichung} & \textcolor{red}{$---$} & \O $\thinspace \textcolor{mygreen}{0.0 \%}$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $30min$}
\label{}
\end{subfigure}
% $\quad\quad\quad\quad$
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $ \textcolor{red}{0 \%}$ & $ \textcolor{mygreen}{100 \%}$ \\ \hline
    \textbf{Laufzeit} & \textcolor{red}{$---$} & \O $\thinspace \textcolor{mygreen}{1185.9  s}$ \\ \hline
    \textbf{Abweichung} & \textcolor{red}{$---$} & \O $\thinspace \textcolor{mygreen}{0.0 \%}$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $45min$}
\label{}
\end{subfigure}

\caption{}
\label{fig:res_b=2_l}
\end{figure}

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.4\textwidth}
\centering
\includegraphics[width=1.3\textwidth]{img/solver_instance_time_b=2_l_2700s.png}
\caption{\textsc{Laufzeiten bei $45min$ Limit}}
\label{fig:b=2_l_runtimes}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.4\textwidth}
\centering
\includegraphics[width=1.3\textwidth]{img/solver_instance_cost_b=2_l_2700s.png}
\caption{\textsc{Kosten bei $45min$ Limit}}
\label{fig:b=2_l_costs}
\end{subfigure}
\caption{}
\label{fig:res_plots_b=2_l}
\end{figure}

\subsection{Konstruktive Heuristik ($b = 3$)}
\label{sec:three_cap_heuristic}

In diesem Abschnitt wird die konstruktive Heuristik zur Lösung von Stacking-Problemen
mit Stacks der Kapazität $b = 3$ vorgestellt. Viele der Ansätze funktionieren analog zur Heuristik für $b = 2$
aus Kapitel \ref{sec:two_cap_heuristic}.

Zunächst wird, wie auch im $b = 2$ - Fall ein Stacking-Constraint-Graph $G = (V, E)$ generiert, welcher die Items
als Knoten enthält, d.h. $V = I$. Dieser Graph enthält ebenfalls eine Kante $\{i, j\}$ zwischen zwei Knoten,
wenn die entsprechenden Items $i, j \in I$ in mindestens einer Richtung stackbar sind, d.h. wenn $s_{ij} + s_{ji} \geq 1$.

Nun berechnet man ebenfalls analog zum $b = 2$ - Fall ein \textsc{MCM} in $G$ und interpretiert dessen Kanten als Paare von Items.
Da die Stacks nun aber nicht nur Paare, sondern Tripel beinhalten können, wird im nächsten Schritt versucht, eben solche Tripel von
kompatiblen Items zu generieren. Dafür wird zunächst ein weiterer Graph $G_1$ generiert, der die zuvor generierten Item-Paare
und die Unmatched Items als Knoten enthält. Dieser Graph enthält eine Kante zwischen einem Item-Paar und einem Unmatched Item,
wenn diese kompatibel sind, d.h., wenn das Unmatched Item dem Paar zugeordnet werden kann und ein Tripel entsteht, welches
stapelbar ist, also die Stacking Constraints respektiert.

Anschließend wird in $G_1$ ein \textsc{MCM} berechnet, dessen Kanten einer größtmöglichen Menge an kompatiblen Item-Tripeln entspricht.
Die verbleibenden Item-Paare, für die kein passendes Unmatched Item gefunden wurde, werden nun in einem weiteren Schritt,
wenn möglich, zu Tripeln gemergt. (TODO: Merge-Step vorstellen).

Da im Zuge des Merge-Prozesses erneut Unmatched Items entstehen können und auch nicht unbedingt sämtliche vorherigen Unmatched Items
einem Paar zugeordnet wurden, werden nun erneut aus allen verbleibenden Items Paare gebildet, was erneut durch ein \textsc{MCM} geschieht.
Die dabei entstehenden Unmatched Items werden dann als unmatched betrachtet.

An dieser Stelle gibt es also eine Menge an Tripeln, eine Menge an Paaren und eine Menge an Unmatched Items. Diese müssen nun natürlich
noch Stacks zugewiesen werden. Diese Zuweisung muss außerdem den Placement Constraints entsprechen.

Dafür wird ein bipartiter Graph generiert, welcher die Items, bestehend aus Tripeln, Paaren und Unmatched Items, in der einen Partition
und die Stacks in der anderen Partition enthält. Dabei gibt es, wie schon bei $b = 2$ initial eine Kante von jedem Tripel, Paar und Item zu
jedem Stack. D.h. im Prinzip sind sämtliche Items mit jedem Stack kompatibel. Dies liegt daran, dass die Placement Constraints indirekt über
hohe Kosten implementiert wurden und nicht direkt durch ein Vermeiden der Kante. Diese Entscheidung wurde getroffen, weil der Algorithmus,
mit dem das \textsc{MWPM} auf diesem Graphen berechnet wird, einen vollständigen bipartiten Graphen als Eingabe erwartet, also einen Graphen,
der jeden Knoten der einen Partition mit jedem Knoten der anderen Partition verbindet. Die inkompatiblen Item-Stack-Zuweisungen werden
also indirekt durch das \textsc{MWPM} ausgeschlossen, wenn möglich.

Dies entspricht auch bereits dem nächsten Schritt - es wird ein \textsc{MWPM} im bipartiten Graphen berechnet, dessen Kanten
als Stack-Zuweisungen interpretiert werden. Zuletzt muss dann erneut die ggf. die Reihenfolge innerhalb der Stacks so angepasst werden,
dass sie die Placement Constraints respektiert. Was jedoch trivial durch den Algorithmus \ref{alg:algo1} möglich ist.

\textbf{Beispiel}

$\boldsymbol{I} := \{0, 1, 2, 3, 4, 5, 6, 7, 8, 9\} \quad\quad\quad \boldsymbol{b} := 3 \quad\quad\quad \boldsymbol{m} := 4$

Zunächst wird das \textsc{MCM} auf dem Stacking-Constraint-Graph berechnet.
In Abb. \ref{fig:pairs_and_unmatched} sieht man das Ergebnis, bei dem die Kanten des \textsc{MCM} als Item-Paare interpretiert wurden.

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.65, transform shape, node distance=2cm]
        \node[state] (A) [thick] {$\boldsymbol{\textcolor{mygreen}{0, 2}}$};
        \node[state] (B) [thick, right of=A] {$\boldsymbol{\textcolor{mygreen}{1, 9}}$};
        \node[state] (C) [thick, right of=B] {$\boldsymbol{\textcolor{mygreen}{3, 4}}$};
        \node[state] (D) [thick, right of=C] {$\boldsymbol{\textcolor{mygreen}{5, 6}}$};
        \node[state] (E) [thick, right of=D] {$\boldsymbol{\textcolor{red}{7}}$};
        \node[state] (F) [thick, right of=E] {$\boldsymbol{\textcolor{red}{8}}$};
        \path;
\end{tikzpicture}
\caption{\textsc{Item-Paare und Unmatched-Items.}}
\label{fig:pairs_and_unmatched}
\end{figure}

Anschließend wird der in Abb. \ref{fig:mcm_for_pairs_and_unmatched} dargestellte Graph generiert, welcher die Paare und
Unmatched Items als Knoten enthält. Eine Kante zwischen einem Unmatched Item und einem Paar bedeutet, dass dieses Unmatched
Item dem Paar zugeordnet werden kann, sodass ein kompatibles Tripel entsteht.
In diesem Fall ist also lediglich die $7$ kompatibel zu zwei Paaren, zu $(3, 4)$ und zu $(5, 6)$. Das auf diesem Graph
berechnete \textsc{MCM} ist in grün dargestellt, d.h. die $7$ wird dem Paar $(3, 4)$ zugeordnet.

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.65, transform shape, node distance=2cm]
        \node[state] (A) [thick] {$\boldsymbol{\textcolor{red}{0, 2}}$};
        \node[state] (B) [thick, right of=A] {$\boldsymbol{\textcolor{red}{1, 9}}$};
        \node[state] (C) [thick, right of=B] {$\boldsymbol{\textcolor{mygreen}{3, 4}}$};
        \node[state] (D) [thick, right of =C] {$\boldsymbol{\textcolor{red}{5, 6}}$};
        \node[state] (E) [thick, right of=D] {$\boldsymbol{\textcolor{mygreen}{7}}$};
        \node[state] (F) [thick, right of=E] {$\boldsymbol{\textcolor{red}{8}}$};
        \path
          (E) edge [thick, mygreen, bend right] node {} (C)
          (E) edge [thick] node {} (D);
\end{tikzpicture}
\caption{\textsc{MCM aus Item-Paaren und Unmatched-Items}}
\label{fig:mcm_for_pairs_and_unmatched}
\end{figure}

In Abb. \ref{fig:intermediate_result} ist das Zwischenergebnis bestehend aus Tripeln, Paaren und Unmatched Items dargestellt.

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.65, transform shape, node distance=2cm]
        \node[state] (A) [thick] {$\boldsymbol{3, 4, 7}$};
        \node[state] (B) [thick, right of=A] {$\boldsymbol{0, 2}$};
        \node[state] (C) [thick, right of=B] {$\boldsymbol{1, 9}$};
        \node[state] (D) [thick, right of=C] {$\boldsymbol{5, 6}$};
        \node[state] (E) [thick, right of=D] {$\boldsymbol{8}$};
        \path;
\end{tikzpicture}
\caption{\textsc{Item-Tripel, Item-Paare und Unmatched-Items}}
\label{fig:intermediate_result}
\end{figure}

In \ref{fig:merge_step} wird versucht, die verbleibenden Paare zu Tripeln zu mergen. In diesem Fall ist es möglich,
die verbleibenden Paare aus \ref{fig:item_pairs} zu den kompatiblen Tripeln in \ref{fig:merge_result} zu mergen.

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.4\textwidth}
\centering
\begin{tikzpicture}[scale=0.65, transform shape, node distance=2cm]
        \node[state] (A) [thick] {$\boldsymbol{0, 2}$};
        \node[state] (B) [thick, right of=A] {$\boldsymbol{1, 9}$};
        \node[state] (C) [thick, right of=B] {$\boldsymbol{5, 6}$};
        \path;
\end{tikzpicture}
\caption{\textsc{Item-Paare}}
\label{fig:item_pairs}
\end{subfigure}
\hspace{10pt}
\begin{subfigure}[b]{0.4\textwidth}
\centering
\begin{tikzpicture}[scale=0.65, transform shape, node distance=2cm]
        \node[state] (A) [thick] {$\boldsymbol{0, 5, 6}$};
        \node[state] (B) [thick, right of=A] {$\boldsymbol{2, 1, 9}$};
        \path;
\end{tikzpicture}
\caption{\textsc{Merge-Ergebnis}}
\label{fig:merge_result}
\end{subfigure}
\caption{}
\label{fig:merge_step}
\end{figure}

Nun existieren drei Item-Tripel und ein Unmatched Item, die im Folgenden Stacks zugewiesen werden.
Dafür wird zunächst der vollständig bipartite Graph in Abb. \ref{fig:complete_bipartite} eingeführt.
Dieser Graph enthält die Items bestehend aus drei Tripeln und einem Unmatched Item in der einen Partition
und die Stacks in der anderen. Anschließend wird ein \textsc{MWPM} in diesem Graph berechnet, welches
in Abb. \ref{fig:mwpm} dargestellt ist.

\begin{figure}[H]
% \begin{figure}[H]
\begin{subfigure}[b]{0.4\textwidth}
\centering
\begin{tikzpicture}[scale=0.65, transform shape, node distance=2cm]
        \node[state] (A) [thick] {$\boldsymbol{3, 4, 7}$};
        \node[state] (B) [thick, below of=A] {$\boldsymbol{0, 5, 6}$};
        \node[state] (C) [thick, below of=B] {$\boldsymbol{2, 1, 9}$};
        \node[state] (D) [thick, below of=C] {$\boldsymbol{8}$};

        \node[state] (E) [thick, right = 4cm of A] {$\boldsymbol{S_1}$};
        \node[state] (F) [thick, below of=E] {$\boldsymbol{S_2}$};
        \node[state] (G) [thick, below of=F] {$\boldsymbol{S_3}$};
        \node[state] (H) [thick, below of=G] {$\boldsymbol{S_4}$};

        \path
          (A) edge [thick] node {} (E)
          (A) edge [thick] node {} (F)
          (A) edge [thick] node {} (G)
          (A) edge [thick] node {} (H)

          (B) edge [thick] node {} (E)
          (B) edge [thick] node {} (F)
          (B) edge [thick] node {} (G)
          (B) edge [thick] node {} (H)

          (C) edge [thick] node {} (E)
          (C) edge [thick] node {} (F)
          (C) edge [thick] node {} (G)
          (C) edge [thick] node {} (H)

          (D) edge [thick] node {} (E)
          (D) edge [thick] node {} (F)
          (D) edge [thick] node {} (G)
          (D) edge [thick] node {} (H);
\end{tikzpicture}
\caption{\textsc{Vollständig Bipartit}}
\label{fig:complete_bipartite}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.4\textwidth}
\centering
\begin{tikzpicture}[scale=0.65, transform shape, node distance=2cm]
        \node[state] (A) [thick] {$\boldsymbol{3, 4, 7}$};
        \node[state] (B) [thick, below of=A] {$\boldsymbol{0, 5, 6}$};
        \node[state] (C) [thick, below of=B] {$\boldsymbol{2, 1, 9}$};
        \node[state] (D) [thick, below of=C] {$\boldsymbol{8}$};

        \node[state] (E) [thick, right = 4cm of A] {$\boldsymbol{S_1}$};
        \node[state] (F) [thick, below of=E] {$\boldsymbol{S_2}$};
        \node[state] (G) [thick, below of=F] {$\boldsymbol{S_3}$};
        \node[state] (H) [thick, below of=G] {$\boldsymbol{S_4}$};

        \path
          (A) edge [thick] node {} (H)
          (B) edge [thick] node {} (F)
          (C) edge [thick] node {} (G)
          (D) edge [thick] node {} (E);
\end{tikzpicture}
\caption{\textsc{MWPM}}
\label{fig:mwpm}
\end{subfigure}
\caption{}
\label{}
\end{figure}

Die Kanten des \textsc{MWPM} werden nun erneut als Stack-Zuweisungen interpretiert.
Die daraus resultierende Stacking-Lösung ist in Abb. \ref{fig:valid_solution} abgebildet. Wobei erneut gegebenenfalls die Reihenfolge
innerhalb der Stacks angepasst werden muss.

\begin{figure}[H]
  \centering
  \resizebox{0.35\textwidth}{!}{
    \begin{tabular}{c|c|c|c|c|}
    \cline{2-5}
    $\boldsymbol{L_3}$ & $$ & $6$ & $9$ & $7$ \\ \cline{2-5}
    $\boldsymbol{L_2}$ & $$ & $5$ & $1$ & $4$ \\ \cline{2-5}
    $\boldsymbol{L_1}$ & $8$ & $0$ & $2$ & $3$ \\ \cline{2-5}
    \multicolumn{1}{c}{} & \multicolumn{1}{c}{$\boldsymbol{S_1}$} & \multicolumn{1}{c}{$\boldsymbol{S_2}$}
    & \multicolumn{1}{c}{$\boldsymbol{S_3}$} & \multicolumn{1}{c}{$\boldsymbol{S_4}$} \\
    \end{tabular}}
    \caption{\textsc{Zulässige Zuweisungen}}
    \label{fig:valid_solution}
\end{figure}

\pagebreak

\subsection{Vergleich der $b = 3$ Solver}
\label{sec:solver_comp_b=3}

In diesem Kapitel werden die verschiedenen Solver für Instanzen mit einer Stack-Kapazität von $b = 3$ miteinander verglichen.

\textbf{Kleine Instanzen (s)}

In Abb. \ref{fig:instance_coverage_b=3_s} ist die Instance-Coverage dargestellt und man erkennt, dass die Bin-Packing-Formulierung
bei den kleinen Instanzen schneller ist als die 3-Index-Formulierung. Grundsätzlich gilt allerdings, dass sämtliche Solver bei einem
Zeitlimit von nur $10s$ alle Instanzen lösen.

\begin{figure}[H]
\centering

\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=3_s_3s.png}
\caption{\textsc{Zeitlimit} $3s$}
\label{}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=3_s_5s.png}
\caption{\textsc{Zeitlimit} $5s$}
\label{}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=3_s_10s.png}
\caption{\textsc{Zeitlimit} $10s$}
\label{}
\end{subfigure}

\caption{}
\label{fig:instance_coverage_b=3_s}
\end{figure}

In Abb. \ref{fig:mip_results_b=3_s} kann man entnehmen, dass die Bin-Packing-Formulierung nach durchschnittlich
$3.1s$ sämtliche Instanzen optimal löst. Bei einem Zeitlimit von $10s$ löst die 3-Index-Formulierung zwar auch
sämtliche Instanzen, allerdings nur $85 \%$ optimal. Dafür benötigt diese eine durchschnittliche Laufzeit von
$5.6s$. D.h. die Bin-Packing-Formulierung ist hier der 3-Index-Formulierung zu bevorzugen.

Die Heuristik ist mit einer durchschnittlichen Laufzeit von $0.01s$ deutlich schneller und weicht um
durchschnittlich $2.65 \%$ vom Optimum ab. Dabei handelt es sich sicher um eine akzeptable Abweichung
und um eine enorme Laufzeitverbesserung, aber wie auch schon bei den kleinen Instanzen für eine Stack-Kapazität
von $b = 2$ gilt auch hier, dass die durchschnittlich benötigten $3.1s$ für die exakte Lösung seitens der
Bin-Packing-Formulierung aus praktischer Perspektive vermutlich akzeptabel sind und kein wirklicher Bedarf
für eine Laufzeitvebessrung durch eine Heuristik vorliegt.

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.4\textwidth}
\centering
\includegraphics[width=1.3\textwidth]{img/solver_instance_time_b=3_s_10s.png}
\caption{\textsc{Laufzeiten bei 10s Zeitlimit}}
\label{fig:b=3_s_runtimes}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.4\textwidth}
\centering
\includegraphics[width=1.3\textwidth]{img/solver_instance_cost_b=3_s_10s.png}
\caption{\textsc{Kosten bei 10s Zeitlimit}}
\label{fig:b=3_s_costs}
\end{subfigure}
\caption{}
\end{figure}

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $\textcolor{mygreen}{40 \%}$ & $\textcolor{red}{5 \%}$ \\ \hline
    \textbf{Laufzeit} & \O $\thinspace 2.9 s$ & \O $\thinspace 2.9 s$ \\ \hline
    \textbf{Abweichung} & \O $\thinspace \textcolor{mygreen}{1.7 \%}$ & \O $\thinspace \textcolor{red}{7.8 \%}$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $3s$}
\label{}
\end{subfigure}
% \end{figure}
% \begin{figure}[H]
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $\textcolor{mygreen}{100 \%}$ & $\textcolor{red}{50 \%}$ \\ \hline
    \textbf{Laufzeit} & \O $\thinspace \textcolor{mygreen}{3.1 s}$ & \O $\thinspace \textcolor{red}{4.0 s}$ \\ \hline
    \textbf{Abweichung} & \O $\thinspace \textcolor{mygreen}{0.0 \%}$ & \O $\thinspace \textcolor{red}{1.2 \%}$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $5s$}
\label{}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $ \textcolor{mygreen}{100 \%}$ & $ \textcolor{red}{85 \%}$ \\ \hline
    \textbf{Laufzeit} & \O $\thinspace \textcolor{mygreen}{3.1 s}$ & \O $\thinspace \textcolor{red}{5.6 s}$ \\ \hline
    \textbf{Abweichung} & \O $\thinspace \textcolor{mygreen}{0.0 \%}$ & \O $\thinspace \textcolor{red}{0.5 \%}$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $10s$}
\label{}
\end{subfigure}
\caption{}
\label{fig:mip_results_b=3_s}
\end{figure}

\textbf{Mittelgroße Instanzen (m)}

In der Kategorie der mittelgroßen Instanzen wurden Zeitlimits von $10$, $20$ und $30$ Minuten betrachtet.
In Abb. \ref{fig:instance_coverage_b=3_s} ist klar zu erkennen, dass die Bin-Packing-Formulierung erfolgsversprechender
als die 3-Index-Formulierung ist, die selbst bei einem Zeitlimit von $30$ Minuten nur $40 \%$ der Instanzen löst.

\begin{figure}[H]
\centering

\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=3_m_600s.png}
\caption{\textsc{Zeitlimit} $10min$}
\label{}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=3_m_1200s.png}
\caption{\textsc{Zeitlimit} $20min$}
\label{}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=3_m_1800s.png}
\caption{\textsc{Zeitlimit} $30min$}
\label{}
\end{subfigure}

\caption{}
\label{fig:instance_coverage_b=3_s}
\end{figure}

Wie man Abb. \ref{fig:mip_results_b=3_s} entnehmen kann, löst die Bin-Packing-Formulierung mit einer durchschnittlichen
Laufzeit von ca. $13$ Minuten sämtliche Instanzen optimal. Daher ist diese der 3-Index-Formulierung hier klar zu bevorzugen, die bei
einem Zeitlimit von $30$ Minuten nur $35 \%$ der Instanzen optimal löst.

Die Heuristik benötigt durchschnittlich eine Laufzeit von nur $0.2s$ und weicht dabei um durchschnittlich
$1.02 \%$ vom Optimum ab. Wie auch schon beim $b = 2$ Szenario ist dieser erhebliche Laufzeitunterschied
vermutlich hinreichende Motivation, um diesen geringe Abweichung vom Optimalwert in Kauf zu nehmen.

\begin{figure}[H]
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $ \textcolor{mygreen}{20 \%}$ & $ \textcolor{red}{10 \%}$ \\ \hline
    \textbf{Laufzeit} & \O $\thinspace \textcolor{red}{583.7 s}$ & \O $\thinspace \textcolor{mygreen}{554.3 s}$ \\ \hline
    \textbf{Abweichung} & \O $\thinspace \textcolor{red}{0.2 \%}$ & \O $\thinspace \textcolor{mygreen}{0.01 \%}$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $10min$}
\label{}
\end{subfigure}
% $\quad\quad\quad\quad$
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $ \textcolor{mygreen}{100 \%}$ & $ \textcolor{red}{30 \%}$ \\ \hline
    \textbf{Laufzeit} & \O $\thinspace \textcolor{mygreen}{791.4 s}$ & \O $\thinspace \textcolor{red}{795.4 s}$ \\ \hline
    \textbf{Abweichung} & \O $\thinspace 0.0 \%$ & \O $\thinspace 0.0 \%$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $20min$}
\label{}
\end{subfigure}
% \end{figure}
% \begin{figure}[H]
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $ \textcolor{mygreen}{100 \%}$ & $ \textcolor{red}{35 \%}$ \\ \hline
    \textbf{Laufzeit} & \O $\thinspace \textcolor{mygreen}{766.4 s}$ & \O $\thinspace \textcolor{red}{874.0 s}$ \\ \hline
    \textbf{Abweichung} & \O $\thinspace 0.0 \%$ & \O $\thinspace 0.0 \%$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $30min$}
\label{}
\end{subfigure}

\caption{}
\label{fig:mip_results_b=3_m}
\end{figure}

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.4\textwidth}
\centering
\includegraphics[width=1.3\textwidth]{img/solver_instance_time_b=3_m_1800s.png}
\caption{\textsc{Laufzeiten bei 30min Limit}}
\label{fig:b=3_m_runtimes}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.4\textwidth}
\centering
\includegraphics[width=1.3\textwidth]{img/solver_instance_cost_b=3_m_1800s.png}
\caption{\textsc{Kosten bei 30min Limit}}
\label{fig:b=3_m_costs}
\end{subfigure}
\caption{}
\end{figure}

\pagebreak

\textbf{Große Instanzen (l)}

\begin{figure}[H]
\centering

\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=3_l_1800s.png}
\caption{\textsc{Zeitlimit} $30min$}
\label{fig:instance_coverage_b=3_l_a}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/solver_instance_coverage_b=3_l_2700s.png}
\caption{\textsc{Zeitlimit} $45min$}
\label{fig:instance_coverage_b=3_l_b}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.3\textwidth}
\centering
\includegraphics[width=1.2\textwidth]{img/na.png}
\caption{\textsc{Zeitlimit} $60min$}
\label{fig:instance_coverage_b=3_l_c}
\end{subfigure}

\caption{}
\label{}
\end{figure}

\begin{figure}[H]
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $ \textcolor{red}{0 \%}$ & $ \textcolor{red}{0 \%}$ \\ \hline
    \textbf{Laufzeit} & $\textcolor{red}{---}$ & $\textcolor{red}{---}$ \\ \hline
    \textbf{Abweichung} & $\textcolor{red}{---}$ & $\textcolor{red}{---}$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $30min$}
\label{}
\end{subfigure}
% $\quad\quad\quad\quad$
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $ \textcolor{red}{0 \%}$ & $ \textcolor{red}{0 \%}$ \\ \hline
    \textbf{Laufzeit} & $\textcolor{red}{---}$ & $\textcolor{red}{---}$ \\ \hline
    \textbf{Abweichung} & $\textcolor{red}{---}$ &$\textcolor{red}{---}$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $45min$}
\label{}
\end{subfigure}
% \end{figure}
% \begin{figure}[H]
\begin{subfigure}[b]{0.3\textwidth}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ | l | l | l |}
    \hline
     & \textbf{BinP} & \textbf{3Idx} \\ \hline
    \textbf{Optimal} & $-tbd-$ & $-tbd-$ \\ \hline
    \textbf{Laufzeit} & $-tbd-$ & $-tbd-$ \\ \hline
    \textbf{Abweichung} & $-tbd-$ & $-tbd-$ \\ \hline
\end{tabular}}
\caption{\textsc{Zeitlimit} $60min$}
\label{}
\end{subfigure}
\end{figure}
